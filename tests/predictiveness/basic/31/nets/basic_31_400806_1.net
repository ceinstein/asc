FANN_FLO_2.1
num_layers=3
learning_rate=0.699993
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=0
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=16
cascade_activation_steepnesses=0.00000000000000000000e+00 0.00000000000000000000e+00 0.00000000000000000000e+00 2.00000000000000000000e+00 6.08100000000000000000e+03 6.08200000000000000000e+03 0.00000000000000000000e+00 0.00000000000000000000e+00 6.00000000000000000000e+00 1.07597200000000000000e+06 1.07622800000000000000e+06 1.07654500000000000000e+06 1.07654600000000000000e+06 1.07680100000000000000e+06 1.07680200000000000000e+06 0.00000000000000000000e+00 
layer_sizes=9 9 9 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 3.38481292128562927246e-02) (1, 6.54707476496696472168e-02) (2, -7.08869099617004394531e-03) (3, -7.59214460849761962891e-02) (4, -7.35553354024887084961e-02) (5, -7.30408430099487304688e-02) (6, -5.38621395826339721680e-02) (7, -9.10092219710350036621e-02) (8, -2.29192897677421569824e-02) (0, 1.02265719324350357056e-02) (1, -5.46394102275371551514e-02) (2, 3.88597734272480010986e-02) (3, 1.49553176015615463257e-02) (4, 4.43285480141639709473e-02) (5, -7.35608637332916259766e-02) (6, -3.47845740616321563721e-02) (7, -3.70461493730545043945e-02) (8, -3.79158705472946166992e-02) (0, -5.38529865443706512451e-02) (1, -1.08289187774062156677e-02) (2, 8.16190764307975769043e-02) (3, 3.39062921702861785889e-02) (4, 1.83332487940788269043e-02) (5, 6.40593795105814933777e-03) (6, -3.78438644111156463623e-02) (7, 2.10679024457931518555e-02) (8, -2.07640007138252258301e-02) (0, 1.56806949526071548462e-02) (1, 7.87514820694923400879e-02) (2, -8.24169535189867019653e-03) (3, -1.84904169291257858276e-02) (4, 8.64093378186225891113e-03) (5, -4.27709519863128662109e-02) (6, 7.44208991527557373047e-02) (7, 4.52640280127525329590e-02) (8, -2.02849805355072021484e-02) (0, -7.19601735472679138184e-02) (1, -7.95503258705139160156e-02) (2, 1.77535898983478546143e-02) (3, 1.76650900393724441528e-02) (4, 5.70088289678096771240e-02) (5, 6.31141811609268188477e-02) (6, -4.34751398861408233643e-02) (7, -1.18598146364092826843e-02) (8, 3.37753072381019592285e-02) (0, -2.91492659598588943481e-02) (1, 5.93751184642314910889e-02) (2, -9.72513332962989807129e-02) (3, 4.91109192371368408203e-02) (4, 7.35238641500473022461e-02) (5, -8.08025058358907699585e-03) (6, 3.07299904525279998779e-02) (7, -2.26113982498645782471e-02) (8, 7.82547369599342346191e-02) (0, -5.50282895565032958984e-02) (1, 1.14599112421274185181e-02) (2, -2.87621971219778060913e-02) (3, -5.83383720368146896362e-03) (4, -5.04770986735820770264e-02) (5, -5.00107184052467346191e-02) (6, 8.59244763851165771484e-02) (7, 4.75357323884963989258e-02) (8, 8.10125023126602172852e-02) (0, -4.36489805579185485840e-02) (1, 3.25808040797710418701e-02) (2, 3.69007103145122528076e-02) (3, 5.25692738592624664307e-02) (4, 6.95406571030616760254e-02) (5, 5.73503971099853515625e-02) (6, -2.96771340072154998779e-02) (7, -2.29507870972156524658e-02) (8, 2.32792515307664871216e-02) (9, -1.05305895209312438965e-01) (10, 9.72730107605457305908e-03) (11, 6.14652521908283233643e-02) (12, 5.72795830667018890381e-02) (13, 6.95870816707611083984e-02) (14, 5.96738345921039581299e-02) (15, 4.71599623560905456543e-02) (16, 2.20219455659389495850e-02) (17, 2.06685438752174377441e-01) (9, -8.68592336773872375488e-02) (10, -3.37545759975910186768e-02) (11, 7.58343189954757690430e-02) (12, -6.79970756173133850098e-02) (13, -7.50460335984826087952e-03) (14, 2.58127730339765548706e-02) (15, -9.52320918440818786621e-03) (16, 8.21386501193046569824e-02) (17, 2.39596605300903320312e-01) (9, 1.50072257965803146362e-02) (10, 7.35533833503723144531e-02) (11, -2.69543752074241638184e-02) (12, 2.79434844851493835449e-02) (13, -1.01733103394508361816e-01) (14, -5.67000284790992736816e-02) (15, -4.76397238671779632568e-02) (16, 3.30860093235969543457e-02) (17, 2.60171592235565185547e-01) (9, -7.60898292064666748047e-02) (10, 8.47433507442474365234e-02) (11, -4.42990660667419433594e-02) (12, -1.23855751007795333862e-02) (13, -8.74395370483398437500e-02) (14, 1.96819528937339782715e-02) (15, -1.68251320719718933105e-02) (16, 4.91187348961830139160e-02) (17, -1.81443274021148681641e-01) (9, -8.94302725791931152344e-02) (10, -1.08800427988171577454e-02) (11, -7.80989527702331542969e-02) (12, 6.89266398549079895020e-02) (13, 8.03970173001289367676e-03) (14, 2.39774174988269805908e-02) (15, 5.16702644526958465576e-02) (16, 2.23484169691801071167e-02) (17, 1.05840452015399932861e-01) (9, -6.65679275989532470703e-02) (10, -8.17106738686561584473e-02) (11, 7.27524906396865844727e-02) (12, -7.69037753343582153320e-02) (13, 3.96915450692176818848e-02) (14, 7.91229382157325744629e-02) (15, 3.63782909698784351349e-03) (16, -4.97494302690029144287e-02) (17, 2.52762615680694580078e-01) (9, 4.30201739072799682617e-02) (10, -3.02644725888967514038e-03) (11, 2.71019656211137771606e-02) (12, -2.03253347426652908325e-02) (13, 1.35818542912602424622e-02) (14, -2.19596195966005325317e-02) (15, 2.68970206379890441895e-02) (16, -8.01320001482963562012e-02) (17, -1.91304385662078857422e-01) (9, -8.61201994121074676514e-03) (10, -1.88653822988271713257e-03) (11, -3.56967374682426452637e-02) (12, 6.84883147478103637695e-02) (13, 4.23453524708747863770e-02) (14, 9.28973779082298278809e-03) (15, -7.49087631702423095703e-02) (16, -1.05441762134432792664e-02) (17, -2.44369611144065856934e-01) 
