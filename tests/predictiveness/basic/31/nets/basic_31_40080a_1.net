FANN_FLO_2.1
num_layers=3
learning_rate=0.699993
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=0
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=16
cascade_activation_steepnesses=0.00000000000000000000e+00 0.00000000000000000000e+00 0.00000000000000000000e+00 2.00000000000000000000e+00 6.08100000000000000000e+03 6.08200000000000000000e+03 0.00000000000000000000e+00 0.00000000000000000000e+00 6.00000000000000000000e+00 1.07597200000000000000e+06 1.07622800000000000000e+06 1.07654500000000000000e+06 1.07654600000000000000e+06 1.07680100000000000000e+06 1.07680200000000000000e+06 0.00000000000000000000e+00 
layer_sizes=9 9 9 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 4.80249524116516113281e-02) (1, 8.66392776370048522949e-02) (2, -6.09372034668922424316e-02) (3, 4.05125617980957031250e-02) (4, 5.54458275437355041504e-02) (5, -3.96719574928283691406e-02) (6, -3.81827354431152343750e-02) (7, 8.23186617344617843628e-03) (8, -2.12037730962038040161e-02) (0, -2.01794169843196868896e-02) (1, 8.02384018898010253906e-02) (2, 5.56772239506244659424e-02) (3, -7.64629393815994262695e-02) (4, 4.16926890611648559570e-02) (5, 6.62424555048346519470e-03) (6, -2.71513611078262329102e-02) (7, 1.09388947486877441406e-01) (8, -7.67359733581542968750e-02) (0, -4.60113584995269775391e-02) (1, -6.85654208064079284668e-02) (2, 1.99819337576627731323e-02) (3, 1.80431287735700607300e-02) (4, 8.53135436773300170898e-02) (5, 1.75071961712092161179e-03) (6, 4.51438203454017639160e-02) (7, -6.67245015501976013184e-02) (8, -8.89280065894126892090e-02) (0, -5.54809719324111938477e-03) (1, 9.04565975069999694824e-02) (2, 3.61760035157203674316e-02) (3, 5.51182031631469726562e-02) (4, 5.05292527377605438232e-02) (5, 2.28152759373188018799e-02) (6, 9.41810011863708496094e-02) (7, -3.13057154417037963867e-02) (8, -9.69119369983673095703e-03) (0, -7.78523087501525878906e-02) (1, -2.62312237173318862915e-02) (2, 4.17979024350643157959e-02) (3, -2.14036125689744949341e-02) (4, 3.32463495433330535889e-02) (5, 2.20363028347492218018e-02) (6, -6.57263994216918945312e-02) (7, 3.44065055251121520996e-02) (8, -5.66140227019786834717e-02) (0, 5.54306805133819580078e-02) (1, 8.28443542122840881348e-02) (2, -7.16358721256256103516e-02) (3, 5.63178136944770812988e-02) (4, -4.29048761725425720215e-02) (5, -4.02012951672077178955e-02) (6, -2.37002428621053695679e-02) (7, 7.88336619734764099121e-02) (8, -3.46256271004676818848e-02) (0, 4.89504151046276092529e-02) (1, 1.11061576753854751587e-02) (2, -1.42214540392160415649e-02) (3, 6.37178197503089904785e-02) (4, 5.86294941604137420654e-02) (5, -2.37648617476224899292e-02) (6, -1.06187537312507629395e-04) (7, -2.06475444138050079346e-02) (8, 7.98358246684074401855e-02) (0, -5.88094852864742279053e-02) (1, -4.83284592628479003906e-02) (2, -7.33318105340003967285e-02) (3, -2.89591308683156967163e-03) (4, -2.22665518522262573242e-02) (5, 4.36961650848388671875e-04) (6, -6.10980130732059478760e-02) (7, 5.42959421873092651367e-02) (8, -6.24024756252765655518e-02) (9, 5.11857904493808746338e-02) (10, 6.36922121047973632812e-02) (11, 6.11640885472297668457e-02) (12, 9.14473235607147216797e-02) (13, 4.16356697678565979004e-03) (14, 4.59396280348300933838e-02) (15, -4.73283901810646057129e-02) (16, -5.81641197204589843750e-02) (17, 2.71847307682037353516e-01) (9, -1.96428988128900527954e-02) (10, 5.14250248670578002930e-04) (11, 4.65456396341323852539e-02) (12, 2.79756858944892883301e-02) (13, -3.62494289875030517578e-02) (14, -4.02425937354564666748e-02) (15, -5.04175573587417602539e-02) (16, -6.22648298740386962891e-02) (17, 1.33043676614761352539e-01) (9, -8.75497795641422271729e-03) (10, 5.09720034897327423096e-02) (11, 2.07504201680421829224e-02) (12, -1.75558142364025115967e-02) (13, -1.12061135470867156982e-01) (14, 7.44937732815742492676e-02) (15, 4.43654358386993408203e-02) (16, -2.31353081762790679932e-02) (17, 1.45157828927040100098e-01) (9, -8.12723636627197265625e-02) (10, 4.58893105387687683105e-02) (11, 9.85711961984634399414e-02) (12, -4.84972558915615081787e-02) (13, -7.79651105403900146484e-04) (14, 7.71653950214385986328e-02) (15, -1.18393421173095703125e-01) (16, -2.29165144264698028564e-03) (17, -1.94731310009956359863e-01) (9, 5.34713566303253173828e-02) (10, -1.26856397837400436401e-02) (11, 5.19577339291572570801e-02) (12, 3.97575721144676208496e-02) (13, 7.34534338116645812988e-02) (14, -2.71435379981994628906e-02) (15, 2.28223837912082672119e-02) (16, 4.65307570993900299072e-03) (17, 2.41717994213104248047e-01) (9, 5.14002256095409393311e-02) (10, 2.46874876320362091064e-02) (11, -9.19382348656654357910e-02) (12, 8.22523012757301330566e-02) (13, -7.83962458372116088867e-02) (14, 7.90695026516914367676e-02) (15, 3.85695695877075195312e-02) (16, 7.24330358207225799561e-03) (17, 2.66761541366577148438e-01) (9, -9.62254777550697326660e-03) (10, -4.35443520545959472656e-02) (11, -1.71884056180715560913e-02) (12, 3.87915037572383880615e-02) (13, -3.04248649626970291138e-02) (14, -9.07583683729171752930e-02) (15, 4.25167381763458251953e-05) (16, 1.81996263563632965088e-02) (17, -2.01216354966163635254e-01) (9, 9.43057052791118621826e-03) (10, 2.79556177556514739990e-02) (11, 7.44464024901390075684e-02) (12, -9.37828645110130310059e-02) (13, -1.63658075034618377686e-02) (14, -2.30591706931591033936e-02) (15, 2.71438937634229660034e-02) (16, -6.94855451583862304688e-02) (17, -2.25514620542526245117e-01) 
