FANN_FLO_2.1
num_layers=3
learning_rate=0.699993
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=0
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=16
cascade_activation_steepnesses=0.00000000000000000000e+00 0.00000000000000000000e+00 0.00000000000000000000e+00 2.00000000000000000000e+00 6.08100000000000000000e+03 6.08200000000000000000e+03 0.00000000000000000000e+00 0.00000000000000000000e+00 6.00000000000000000000e+00 1.07597200000000000000e+06 1.07622800000000000000e+06 1.07654500000000000000e+06 1.07654600000000000000e+06 1.07680100000000000000e+06 1.07680200000000000000e+06 0.00000000000000000000e+00 
layer_sizes=9 9 9 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -5.39084188640117645264e-02) (1, 2.22680922597646713257e-02) (2, 4.81324084103107452393e-02) (3, 8.25395882129669189453e-02) (4, -4.04552593827247619629e-02) (5, 9.64971706271171569824e-02) (6, -6.12441860139369964600e-02) (7, -9.03176702558994293213e-03) (8, -5.61321228742599487305e-02) (0, -9.45941433310508728027e-02) (1, 3.80437858402729034424e-02) (2, 3.92884872853755950928e-02) (3, -3.23114022612571716309e-02) (4, 8.55081304907798767090e-02) (5, -4.92576435208320617676e-02) (6, 8.41995626688003540039e-02) (7, 1.91266201436519622803e-02) (8, -4.73209060728549957275e-02) (0, 1.02170743048191070557e-05) (1, 9.93204186670482158661e-04) (2, 7.26674571633338928223e-02) (3, -2.88151688873767852783e-02) (4, 8.97724255919456481934e-02) (5, 2.09605935961008071899e-02) (6, -2.69565042108297348022e-02) (7, 5.38579188287258148193e-02) (8, -7.63845145702362060547e-02) (0, 5.52194379270076751709e-02) (1, 6.72634830698370933533e-03) (2, 3.01353093236684799194e-02) (3, -2.71530151367187500000e-02) (4, 6.07980750501155853271e-02) (5, -4.75965924561023712158e-02) (6, -7.90206044912338256836e-02) (7, 4.40316796302795410156e-02) (8, 1.99283026158809661865e-02) (0, -8.31067711114883422852e-02) (1, 7.61954113841056823730e-02) (2, -9.56955626606941223145e-02) (3, -3.85448671877384185791e-02) (4, 8.44210460782051086426e-02) (5, 4.23482172191143035889e-02) (6, 1.00743621587753295898e-01) (7, -5.17733618617057800293e-02) (8, 3.06761357933282852173e-02) (0, -4.97021563351154327393e-02) (1, -7.81595930457115173340e-02) (2, -6.07830435037612915039e-02) (3, -9.06065572053194046021e-04) (4, 2.60352417826652526855e-02) (5, 4.02101650834083557129e-02) (6, -2.82386168837547302246e-02) (7, 9.58900228142738342285e-02) (8, 3.41671966016292572021e-02) (0, 1.00561723113059997559e-01) (1, -3.79111878573894500732e-02) (2, -1.88195947557687759399e-02) (3, -7.71528407931327819824e-02) (4, -7.66234695911407470703e-02) (5, 8.79067555069923400879e-02) (6, 5.29824718832969665527e-02) (7, -1.10625997185707092285e-02) (8, 5.47731146216392517090e-02) (0, 1.27998381853103637695e-01) (1, -1.07237342745065689087e-02) (2, -2.18357332050800323486e-02) (3, 4.06405441462993621826e-02) (4, 3.54336053133010864258e-02) (5, -4.56403270363807678223e-02) (6, 4.49449755251407623291e-02) (7, 9.01859551668167114258e-02) (8, -3.19551751017570495605e-02) (9, -6.21457174420356750488e-02) (10, 4.73853461444377899170e-02) (11, -2.60455776005983352661e-02) (12, 7.83272907137870788574e-02) (13, 9.32643860578536987305e-02) (14, -1.14643480628728866577e-04) (15, -8.91711264848709106445e-02) (16, -4.18112240731716156006e-03) (17, 1.17236584424972534180e-01) (9, 4.16609719395637512207e-02) (10, 5.20209036767482757568e-02) (11, -9.33198630809783935547e-02) (12, -1.36843333020806312561e-02) (13, 4.02910374104976654053e-02) (14, -2.72638648748397827148e-02) (15, 6.09831772744655609131e-02) (16, 5.84883615374565124512e-02) (17, 1.73653870820999145508e-01) (9, 3.99183854460716247559e-02) (10, -1.16173559799790382385e-02) (11, 5.43605200946331024170e-02) (12, -3.29482252709567546844e-03) (13, -1.85651853680610656738e-02) (14, -5.25532290339469909668e-02) (15, 6.86146169900894165039e-02) (16, 9.44681391119956970215e-02) (17, 2.30245009064674377441e-01) (9, -6.11825175583362579346e-02) (10, -4.31407522410154342651e-03) (11, -3.33070801571011543274e-03) (12, -4.43015620112419128418e-02) (13, 4.60028871893882751465e-02) (14, -5.88383898138999938965e-02) (15, 3.54854017496109008789e-02) (16, 1.30359353497624397278e-02) (17, -2.47085615992546081543e-01) (9, -8.59073176980018615723e-02) (10, 3.51506136357784271240e-02) (11, 2.52711623907089233398e-02) (12, -5.34861348569393157959e-02) (13, -9.02949366718530654907e-03) (14, -1.77794583141803741455e-02) (15, -5.38465902209281921387e-02) (16, 8.33025872707366943359e-02) (17, 1.18635438382625579834e-01) (9, 5.70589769631624221802e-03) (10, 3.78738939762115478516e-02) (11, 6.77626132965087890625e-02) (12, 9.95290353894233703613e-02) (13, -8.63854773342609405518e-03) (14, -3.92287001013755798340e-02) (15, 4.73038367927074432373e-02) (16, 9.36095565557479858398e-02) (17, 2.25402891635894775391e-01) (9, 1.07345923781394958496e-01) (10, 5.79530894756317138672e-02) (11, 2.34141871333122253418e-02) (12, 3.38349044322967529297e-02) (13, 8.32805335521697998047e-02) (14, -8.57429504394531250000e-02) (15, -6.25425651669502258301e-02) (16, -6.70914426445960998535e-02) (17, -1.33818626403808593750e-01) (9, -7.97307584434747695923e-03) (10, 7.49158710241317749023e-02) (11, -1.39833260327577590942e-02) (12, 1.44569147378206253052e-02) (13, -9.86069515347480773926e-02) (14, -8.18940475583076477051e-02) (15, -5.41657619178295135498e-02) (16, -6.37442618608474731445e-02) (17, -1.80428415536880493164e-01) 
