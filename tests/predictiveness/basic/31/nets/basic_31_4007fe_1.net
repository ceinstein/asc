FANN_FLO_2.1
num_layers=3
learning_rate=0.699993
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=0
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=16
cascade_activation_steepnesses=0.00000000000000000000e+00 0.00000000000000000000e+00 0.00000000000000000000e+00 2.00000000000000000000e+00 6.08100000000000000000e+03 6.08200000000000000000e+03 0.00000000000000000000e+00 0.00000000000000000000e+00 6.00000000000000000000e+00 1.07597200000000000000e+06 1.07622800000000000000e+06 1.07654500000000000000e+06 1.07654600000000000000e+06 1.07680100000000000000e+06 1.07680200000000000000e+06 0.00000000000000000000e+00 
layer_sizes=9 9 9 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -6.03401437401771545410e-02) (1, -7.68705978989601135254e-02) (2, -2.62276120483875274658e-02) (3, -3.09478454291820526123e-02) (4, -7.26586729288101196289e-02) (5, 6.22479096055030822754e-02) (6, 9.32214632630348205566e-02) (7, 4.16001211851835250854e-03) (8, 6.54958933591842651367e-02) (0, -5.71136884391307830811e-02) (1, -9.24454629421234130859e-02) (2, 6.90705999732017517090e-02) (3, 5.52035719156265258789e-02) (4, 4.44113276898860931396e-02) (5, 7.37161412835121154785e-02) (6, 4.10662554204463958740e-02) (7, 1.62184163928031921387e-02) (8, -8.53871256113052368164e-02) (0, 3.62399369478225708008e-02) (1, -4.71996739506721496582e-02) (2, -3.06658633053302764893e-02) (3, -3.88861447572708129883e-02) (4, -6.16342425346374511719e-02) (5, -9.62188690900802612305e-02) (6, 7.28931576013565063477e-02) (7, 1.46846622228622436523e-02) (8, -4.87010627985000610352e-02) (0, 1.19273208081722259521e-01) (1, 5.60957454144954681396e-02) (2, 9.67028513550758361816e-02) (3, 7.59487897157669067383e-02) (4, 1.19239561259746551514e-01) (5, -8.01677554845809936523e-02) (6, -5.02788349986076354980e-02) (7, -2.44607925415039062500e-02) (8, -2.93424651026725769043e-02) (0, 9.04704481363296508789e-02) (1, -8.02283063530921936035e-02) (2, 2.58285757154226303101e-02) (3, 4.32138368487358093262e-02) (4, -8.93897004425525665283e-03) (5, 3.33831086754798889160e-02) (6, 1.22844381257891654968e-02) (7, -4.00702096521854400635e-02) (8, 6.19746278971433639526e-03) (0, -4.52621541917324066162e-02) (1, 9.99233946204185485840e-02) (2, -7.86567851901054382324e-02) (3, -1.69840939342975616455e-02) (4, -8.55996087193489074707e-03) (5, -2.58564539253711700439e-02) (6, 5.23500517010688781738e-02) (7, 2.43554990738630294800e-02) (8, -3.22139859199523925781e-02) (0, 5.97906894981861114502e-02) (1, -1.44248371943831443787e-02) (2, 7.07971677184104919434e-02) (3, 8.28912258148193359375e-02) (4, -4.42534759640693664551e-02) (5, 2.68929246813058853149e-02) (6, 7.95940756797790527344e-02) (7, -1.04541167616844177246e-01) (8, -2.96936742961406707764e-03) (0, -5.12724071741104125977e-02) (1, -7.81910717487335205078e-02) (2, 4.91987578570842742920e-02) (3, -1.68513320386409759521e-02) (4, 1.33977413177490234375e-01) (5, 6.89704567193984985352e-02) (6, 1.08977243304252624512e-01) (7, 6.24534226953983306885e-02) (8, -1.82704627513885498047e-02) (9, -1.12083833664655685425e-03) (10, -6.76852613687515258789e-02) (11, -2.71384343504905700684e-02) (12, 9.67445373535156250000e-02) (13, -3.83487204089760780334e-03) (14, -2.97660659998655319214e-03) (15, -6.78775385022163391113e-02) (16, 9.44038927555084228516e-02) (17, 2.80081570148468017578e-01) (9, -1.46116819232702255249e-02) (10, 7.25362971425056457520e-02) (11, 2.05365512520074844360e-02) (12, 7.65025317668914794922e-02) (13, 3.73199880123138427734e-02) (14, -6.81456178426742553711e-02) (15, 6.22054003179073333740e-02) (16, 3.16937565803527832031e-02) (17, 1.86425909399986267090e-01) (9, -3.24621833860874176025e-02) (10, 3.32239940762519836426e-02) (11, -1.65806729346513748169e-02) (12, 8.41021090745925903320e-02) (13, 3.77995632588863372803e-02) (14, 3.04600149393081665039e-02) (15, 4.79107424616813659668e-02) (16, 8.31569433212280273438e-02) (17, 2.10270479321479797363e-01) (9, 1.06898993253707885742e-02) (10, 4.60312180221080780029e-02) (11, -3.34724560379981994629e-02) (12, 4.89345081150531768799e-02) (13, -3.98875810205936431885e-02) (14, -3.65808755159378051758e-02) (15, -7.60240182280540466309e-02) (16, -4.10706959664821624756e-02) (17, -1.34430855512619018555e-01) (9, 2.14470662176609039307e-02) (10, -1.27667533233761787415e-02) (11, 4.06848862767219543457e-02) (12, 2.68022753298282623291e-02) (13, 7.20257908105850219727e-02) (14, 3.03435623645782470703e-02) (15, -1.86477843672037124634e-02) (16, 4.77885417640209197998e-02) (17, 1.57066255807876586914e-01) (9, -1.61281619220972061157e-02) (10, 5.30579546466469764709e-03) (11, 7.13989287614822387695e-02) (12, 8.43245238065719604492e-02) (13, 7.20646232366561889648e-02) (14, 2.20433026552200317383e-02) (15, 1.45150627940893173218e-03) (16, 5.54073676466941833496e-02) (17, 1.50094136595726013184e-01) (9, -8.23150873184204101562e-02) (10, -1.97577029466629028320e-02) (11, -4.73588854074478149414e-02) (12, 3.21453027427196502686e-02) (13, 9.08809676766395568848e-02) (14, 8.31175148487091064453e-02) (15, 6.46966025233268737793e-02) (16, 4.04645465314388275146e-02) (17, -2.37222760915756225586e-01) (9, -4.29112389683723449707e-02) (10, 6.95596039295196533203e-02) (11, 2.99975611269474029541e-02) (12, -8.44572558999061584473e-02) (13, 6.86668278649449348450e-03) (14, 8.09397324919700622559e-02) (15, 5.99435940384864807129e-02) (16, -6.41968622803688049316e-02) (17, -1.41760334372520446777e-01) 
