FANN_FLO_2.1
num_layers=3
learning_rate=0.699993
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=0
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=16
cascade_activation_steepnesses=0.00000000000000000000e+00 0.00000000000000000000e+00 0.00000000000000000000e+00 2.00000000000000000000e+00 6.08100000000000000000e+03 6.08200000000000000000e+03 0.00000000000000000000e+00 0.00000000000000000000e+00 6.00000000000000000000e+00 1.07597200000000000000e+06 1.07622800000000000000e+06 1.07654500000000000000e+06 1.07654600000000000000e+06 1.07680100000000000000e+06 1.07680200000000000000e+06 0.00000000000000000000e+00 
layer_sizes=9 9 9 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.37632133066654205322e-02) (1, 2.17224843800067901611e-02) (2, -5.32512664794921875000e-02) (3, 4.67933043837547302246e-02) (4, -9.70970988273620605469e-02) (5, -7.57693573832511901855e-02) (6, -5.61957322061061859131e-02) (7, -3.70914302766323089600e-02) (8, -7.78619851917028427124e-03) (0, 1.10264047980308532715e-01) (1, -4.47746701538562774658e-02) (2, 9.72250476479530334473e-02) (3, 4.47606965899467468262e-02) (4, 9.54765006899833679199e-02) (5, 2.90332678705453872681e-02) (6, 1.91490203142166137695e-02) (7, 1.01526312530040740967e-01) (8, -1.74249559640884399414e-02) (0, 7.14859217405319213867e-02) (1, 4.18437384068965911865e-02) (2, -1.53945153579115867615e-02) (3, 5.65959662199020385742e-02) (4, 9.06360819935798645020e-02) (5, -5.61432540416717529297e-02) (6, 7.26435855031013488770e-02) (7, 1.06531225144863128662e-01) (8, 1.35049056261777877808e-02) (0, -2.70864907652139663696e-02) (1, 1.93208344280719757080e-02) (2, 4.70633618533611297607e-02) (3, 4.42352406680583953857e-02) (4, 8.92361402511596679688e-02) (5, -3.12141608446836471558e-02) (6, 9.09839794039726257324e-02) (7, 3.31509113311767578125e-02) (8, -3.46327312290668487549e-02) (0, -6.68251663446426391602e-02) (1, 7.75195881724357604980e-02) (2, 2.88402568548917770386e-02) (3, 2.25101020187139511108e-02) (4, 8.97271335124969482422e-02) (5, 8.40655788779258728027e-02) (6, 1.97351481765508651733e-02) (7, 2.19140667468309402466e-02) (8, 8.14855843782424926758e-02) (0, -6.94321990013122558594e-02) (1, -8.60279574990272521973e-02) (2, 5.59208504855632781982e-02) (3, 5.69076975807547569275e-04) (4, 7.34457001090049743652e-02) (5, -2.23541259765625000000e-03) (6, 8.51745605468750000000e-02) (7, 2.17127390205860137939e-02) (8, -2.36115977168083190918e-02) (0, -6.42733275890350341797e-02) (1, -1.02892583236098289490e-02) (2, -2.17259526252746582031e-02) (3, 4.09026555716991424561e-02) (4, 6.90792277455329895020e-02) (5, 9.75948721170425415039e-02) (6, -1.20339766144752502441e-02) (7, 1.67574100196361541748e-02) (8, 9.32860001921653747559e-02) (0, 5.99172711372375488281e-02) (1, 8.17229785025119781494e-03) (2, 2.68678199499845504761e-02) (3, -7.12725222110748291016e-02) (4, 3.30072976648807525635e-02) (5, 4.38740244135260581970e-03) (6, 5.75677379965782165527e-02) (7, -5.89998699724674224854e-02) (8, -1.42253004014492034912e-02) (9, 1.80592294782400131226e-02) (10, 6.51194602251052856445e-02) (11, 1.19420304894447326660e-01) (12, 2.19867955893278121948e-02) (13, 8.16739350557327270508e-02) (14, -8.90715420246124267578e-02) (15, -3.02747823297977447510e-02) (16, -2.42734570056200027466e-02) (17, 2.59480178356170654297e-01) (9, 3.82375344634056091309e-02) (10, -6.83367066085338592529e-03) (11, 3.68037037551403045654e-02) (12, -4.37213592231273651123e-02) (13, 7.70065421238541603088e-03) (14, 1.03436611592769622803e-01) (15, 2.61466205120086669922e-02) (16, -6.48872926831245422363e-02) (17, 2.45611578226089477539e-01) (9, -6.33820798248052597046e-03) (10, 4.94700297713279724121e-02) (11, 7.28957541286945343018e-03) (12, 2.30022147297859191895e-02) (13, -1.54957594349980354309e-02) (14, 9.17172133922576904297e-02) (15, -5.87789230048656463623e-02) (16, -3.72705259360373020172e-03) (17, 1.99743345379829406738e-01) (9, 5.13600893318653106689e-02) (10, -7.49909058213233947754e-02) (11, 9.69748198986053466797e-03) (12, -1.06817618012428283691e-01) (13, 7.85522311925888061523e-02) (14, -2.73022633045911788940e-02) (15, -1.11460544168949127197e-01) (16, -8.59865453094244003296e-03) (17, -2.28216663002967834473e-01) (9, -1.16995781660079956055e-01) (10, 7.30065554380416870117e-02) (11, 6.95139840245246887207e-02) (12, 9.96223092079162597656e-02) (13, 1.06708062812685966492e-02) (14, -8.64982828497886657715e-02) (15, -5.41509222239255905151e-03) (16, 3.62208411097526550293e-02) (17, 1.92293748259544372559e-01) (9, -4.20749038457870483398e-02) (10, -2.04380936920642852783e-02) (11, 7.47929289937019348145e-02) (12, -4.45643961429595947266e-02) (13, 7.33016729354858398438e-02) (14, -2.54889093339443206787e-02) (15, 1.99838802218437194824e-02) (16, -3.49276997148990631104e-02) (17, 2.28581413626670837402e-01) (9, 7.58095365017652511597e-03) (10, -2.90358830243349075317e-02) (11, -9.37405377626419067383e-02) (12, 7.69632160663604736328e-02) (13, -7.69576132297515869141e-02) (14, -1.96169689297676086426e-02) (15, 2.83559169620275497437e-02) (16, -5.31187579035758972168e-02) (17, -2.12712138891220092773e-01) (9, -5.93535155057907104492e-02) (10, -8.11421722173690795898e-02) (11, 3.27697768807411193848e-02) (12, -3.93916666507720947266e-02) (13, -6.21886253356933593750e-02) (14, 2.25259363651275634766e-03) (15, -9.54379290342330932617e-02) (16, -7.26876333355903625488e-02) (17, -2.67356097698211669922e-01) 
