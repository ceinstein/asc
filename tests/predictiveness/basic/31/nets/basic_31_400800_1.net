FANN_FLO_2.1
num_layers=3
learning_rate=0.699993
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=0
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=16
cascade_activation_steepnesses=0.00000000000000000000e+00 0.00000000000000000000e+00 0.00000000000000000000e+00 2.00000000000000000000e+00 6.08100000000000000000e+03 6.08200000000000000000e+03 0.00000000000000000000e+00 0.00000000000000000000e+00 6.00000000000000000000e+00 1.07597200000000000000e+06 1.07622800000000000000e+06 1.07654500000000000000e+06 1.07654600000000000000e+06 1.07680100000000000000e+06 1.07680200000000000000e+06 0.00000000000000000000e+00 
layer_sizes=9 9 9 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (9, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (9, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.03934325277805328369e-01) (1, 4.46280231699347496033e-03) (2, -8.17849636077880859375e-02) (3, -2.46349982917308807373e-02) (4, -7.65831023454666137695e-02) (5, 3.96328344941139221191e-02) (6, 5.91705329716205596924e-02) (7, 4.31535206735134124756e-03) (8, -3.30983661115169525146e-02) (0, 9.66896414756774902344e-02) (1, -2.38933563232421875000e-02) (2, 2.86929849535226821899e-02) (3, 9.05600637197494506836e-02) (4, -6.04235418140888214111e-02) (5, 3.61643321812152862549e-02) (6, -2.54332274198532104492e-03) (7, -5.92881329357624053955e-02) (8, -2.70840078592300415039e-02) (0, 7.41404145956039428711e-02) (1, 1.13982437178492546082e-02) (2, 3.78190283663570880890e-03) (3, 6.18790090084075927734e-02) (4, 1.10695071518421173096e-01) (5, -3.85754113085567951202e-03) (6, 8.24395120143890380859e-02) (7, 1.96413137018680572510e-04) (8, 8.95234271883964538574e-02) (0, -3.76170352101325988770e-02) (1, 4.92481850087642669678e-02) (2, -4.62027601897716522217e-02) (3, 4.20419573783874511719e-02) (4, 1.84936989098787307739e-02) (5, 5.82600347697734832764e-02) (6, 6.02569952607154846191e-02) (7, -1.18896096944808959961e-01) (8, 4.69881296157836914062e-02) (0, 2.24041882902383804321e-02) (1, 4.94536533951759338379e-02) (2, -3.95173095166683197021e-02) (3, 7.65510275959968566895e-02) (4, 3.24335880577564239502e-02) (5, 3.65893356502056121826e-02) (6, 5.24399802088737487793e-03) (7, 8.70359502732753753662e-03) (8, 6.24560900032520294189e-02) (0, -5.26690930128097534180e-02) (1, 9.12898555397987365723e-02) (2, 8.82975459098815917969e-02) (3, 5.95683790743350982666e-03) (4, 6.11671134829521179199e-02) (5, -3.04210203466936945915e-04) (6, -9.02612656354904174805e-02) (7, 1.22800385579466819763e-02) (8, 6.12770626321434974670e-03) (0, -1.14305340684950351715e-03) (1, -2.25494559854269027710e-02) (2, 8.90551134943962097168e-02) (3, -2.23857127130031585693e-02) (4, 6.12461939454078674316e-02) (5, 3.83032932877540588379e-02) (6, 3.14115174114704132080e-02) (7, 2.52221617847681045532e-02) (8, -2.17903219163417816162e-02) (0, -1.79027244448661804199e-02) (1, 7.93448742479085922241e-03) (2, -1.82310882955789566040e-02) (3, -4.89805862307548522949e-02) (4, -7.83372893929481506348e-02) (5, -6.87774345278739929199e-02) (6, 1.15021001547574996948e-02) (7, -1.02366611361503601074e-01) (8, 5.49801886081695556641e-02) (9, -4.82001826167106628418e-02) (10, 5.56057551875710487366e-03) (11, 6.62750378251075744629e-03) (12, -6.75251260399818420410e-02) (13, 7.17938244342803955078e-02) (14, -4.72460389137268066406e-02) (15, -8.59952792525291442871e-02) (16, -6.26976341009140014648e-02) (17, 1.19244761765003204346e-01) (9, 2.08538724109530448914e-03) (10, -5.04630059003829956055e-02) (11, 5.49953505396842956543e-02) (12, -8.12751799821853637695e-02) (13, 7.19087570905685424805e-02) (14, -1.08430050313472747803e-01) (15, 1.01654700934886932373e-01) (16, -8.06785002350807189941e-02) (17, 2.45054945349693298340e-01) (9, 2.86299791187047958374e-02) (10, 5.85006661713123321533e-02) (11, 2.34986431896686553955e-02) (12, -7.37450271844863891602e-02) (13, -2.57732216268777847290e-02) (14, 8.60422700643539428711e-02) (15, 1.22210616245865821838e-03) (16, -7.74536281824111938477e-04) (17, 1.28694131970405578613e-01) (9, 2.88838967680931091309e-02) (10, -6.31972402334213256836e-02) (11, -1.01974010467529296875e-01) (12, -2.57035903632640838623e-02) (13, -3.08802202343940734863e-02) (14, 5.08528240025043487549e-02) (15, 5.18541783094406127930e-02) (16, 1.90766267478466033936e-02) (17, -1.96952536702156066895e-01) (9, -8.25205594301223754883e-02) (10, 8.41657817363739013672e-03) (11, 7.62746781110763549805e-02) (12, -4.80301156640052795410e-02) (13, -6.20976909995079040527e-02) (14, 8.85338112711906433105e-02) (15, 6.86586499214172363281e-02) (16, -8.77223610877990722656e-02) (17, 2.37176150083541870117e-01) (9, 5.81046789884567260742e-02) (10, -8.49327519536018371582e-02) (11, 1.13595545291900634766e-01) (12, 3.68992388248443603516e-02) (13, 7.06022903323173522949e-02) (14, 3.69615629315376281738e-02) (15, -8.12016576528549194336e-02) (16, 5.23148141801357269287e-02) (17, 2.78078675270080566406e-01) (9, -8.81253331899642944336e-02) (10, -3.78787294030189514160e-02) (11, -2.06584967672824859619e-02) (12, -7.97623246908187866211e-02) (13, 6.36099949479103088379e-02) (14, 5.29771149158477783203e-02) (15, -4.22490872442722320557e-02) (16, -1.74560174345970153809e-02) (17, -2.52621591091156005859e-01) (9, -8.94244536757469177246e-02) (10, -6.61363303661346435547e-02) (11, 5.78618049621582031250e-03) (12, -1.41332363709807395935e-02) (13, -6.84434324502944946289e-02) (14, -3.89733090996742248535e-02) (15, -6.41831383109092712402e-02) (16, 2.07917485386133193970e-03) (17, -2.18758210539817810059e-01) 
